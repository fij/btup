{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free data sets (examples)\n",
    "\n",
    "1. Based on the descriptions at the pages of data providers explain what each data set means.\n",
    "2. Select two data sets, and compare their changes at times when something happened in the world.\n",
    "3. Note: the word `spread` usually means `difference`.\n",
    "\n",
    "| Source | Name, Link to page | Type | Further information |\n",
    "| :--- | :--| :--- | :-- |\n",
    "|[Yahoo Finance](https://finance.yahoo.com) | [S&P500 stock market index](https://finance.yahoo.com/quote/%5EGSPC) | Equity index | US Large cap stocks |\n",
    "| &nbsp; | [Walmart](https://finance.yahoo.com/quote/WMT) | Equity | Retail, Large capitalization |\n",
    "| &nbsp; | [Amazon](https://finance.yahoo.com/quote/AMZN) | Equity | IT, Big cap |\n",
    "| &nbsp; | [Tesla](https://finance.yahoo.com/quote/TSLA) | Equity | Tech / Cars, Big cap |\n",
    "| &nbsp; | [BJ's Restaurants Inc.](https://finance.yahoo.com/quote/BJRI) | Equity | Catering industry, Small cap |\n",
    "| &nbsp; | [Bitcoin](https://finance.yahoo.com/quote/BTC-USD) | FX |  Payments / Investment | \n",
    "| &nbsp; | [Ethereum](https://finance.yahoo.com/quote/ETH-USD) | FX | also infrastructural | \n",
    "| &nbsp; | [Ounce of gold in USD](https://finance.yahoo.com/quote/GC=F) | Commodity | Gold: bullion |\n",
    "| &nbsp; | [YEN / USD exchange rate](https://finance.yahoo.com/quote/JPYUSD=X) | FX | &nbsp; | \n",
    "| &nbsp; | [EUR / USD exchange rate](https://finance.yahoo.com/quote/EUR=X) | FX | &nbsp; |\n",
    "| &nbsp; | [Vanguard real estate index](https://finance.yahoo.com/quote/VNQ) | Real Estate Index| &nbsp; |\n",
    "| &nbsp; | [OTP](https://finance.yahoo.com/quote/OTP.BP) | Equity | Banking, Regional |\n",
    "| &nbsp; | [MOL](https://finance.yahoo.com/quote/MOL.BP) | Equity | Energy, Regional |\n",
    "| &nbsp; | [Telekom HU](https://finance.yahoo.com/quote/MTELEKOM.BP) | Equity | Telco, subsidiary of Deutsche Telekom |\n",
    "| &nbsp; | [Richter](https://finance.yahoo.com/quote/RICHTER.BP) | Equity | Pharma, Regional |\n",
    "| [FRED](https://fred.stlouisfed.org) | [Moody's AAA 10Y credit spread](https://fred.stlouisfed.org/series/AAA10Y) | AAA Corp Bond vs 10Y Treasury  | Spread to 10Y T-bond |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download\n",
    "\n",
    "Please download data to the `data` subfolder of your current local directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yahoo data sets: Download with yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local file is available: data\\^GSPC.csv\n",
      "Local file is available: data\\WMT.csv\n",
      "Local file is available: data\\AMZN.csv\n",
      "Local file is available: data\\TSLA.csv\n",
      "Local file is available: data\\MSFT.csv\n",
      "Local file is available: data\\NVDA.csv\n",
      "Local file is available: data\\BJRI.csv\n",
      "Local file is available: data\\BTC-USD.csv\n",
      "Local file is available: data\\ETH-USD.csv\n",
      "Local file is available: data\\GC=F.csv\n",
      "Local file is available: data\\JPYUSD=X.csv\n",
      "Local file is available: data\\EUR=X.csv\n",
      "Local file is available: data\\VNQ.csv\n",
      "Local file is available: data\\OTP.BD.csv\n",
      "Local file is available: data\\MOL.BD.csv\n",
      "Local file is available: data\\MTELEKOM.BD.csv\n",
      "Local file is available: data\\RICHTER.BD.csv\n"
     ]
    }
   ],
   "source": [
    "if True:  # close entire code block here\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    import yfinance as yf\n",
    "    import time\n",
    "\n",
    "    YAHOO_TICKERS = ['^GSPC', 'WMT', 'AMZN', 'TSLA', 'MSFT', 'NVDA', 'BJRI', 'BTC-USD', 'ETH-USD',\n",
    "                     'GC=F', 'JPYUSD=X', 'EUR=X', 'VNQ',\n",
    "                    'OTP.BD', 'MOL.BD', 'MTELEKOM.BD', 'RICHTER.BD']\n",
    "\n",
    "    for ticker in YAHOO_TICKERS:\n",
    "        local_csv_file_path = Path('data') / f'{ticker}.csv'\n",
    "        if local_csv_file_path.exists():\n",
    "            print(f'Local file is available: {local_csv_file_path}')\n",
    "        else:\n",
    "            time.sleep(5)\n",
    "            data = yf.download(tickers=ticker, period='max')\n",
    "            data.to_csv(local_csv_file_path)\n",
    "            print(f'Downloaded data and saved to local file: {local_csv_file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FRED data: Download manually\n",
    "At https://fred.stlouisfed.org/series/AAA10Y \n",
    "* select frequency `max`\n",
    "* click `Download` in the top right corner\n",
    "* and then select `CSV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data. Daily closing price and traded volume.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "if True:  # close entire code block here\n",
    "    import pandas as pd\n",
    "    from matplotlib import gridspec, pyplot as plt\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from pathlib import Path\n",
    "\n",
    "    # List of currently available files\n",
    "    TICKERS = ['^GSPC', 'WMT', 'AMZN', 'TSLA', 'NVDA', 'BJRI', 'BTC-USD', 'ETH-USD', 'GC=F', 'VNQ', 'MSFT',\n",
    "               'OTP.BD', 'MOL.BD', 'MTELEKOM.BD', 'RICHTER.BD']\n",
    "    TICKERS_SAMPLE = ['NVDA', 'BTC-USD', 'WMT', 'BJRI']\n",
    "    \n",
    "    DATA_FOLDER = 'data'\n",
    "    USD_HUF = 328\n",
    "\n",
    "    data = dict()  # Data for a ticker\n",
    "    for ticker in TICKERS:\n",
    "\n",
    "        # --- Read csv to dataframe ---\n",
    "        df = pd.read_csv(str(Path(DATA_FOLDER) / f'{ticker}.csv'))\n",
    "\n",
    "        # formatting\n",
    "        df = df.drop(df.index[[0, 1]])\n",
    "        df = df.rename(columns={'Price': 'Date'})\n",
    "\n",
    "        # select columns and set their types \n",
    "        df = df[['Date', 'Close', 'Volume']]\n",
    "        df.Date = pd.to_datetime(df.Date)\n",
    "        df.Close = pd.to_numeric(df.Close, errors='coerce')\n",
    "        df.Volume = pd.to_numeric(df.Volume, errors='coerce')\n",
    "\n",
    "        # Convert HUF to USD\n",
    "        if ticker.endswith('.BD'):\n",
    "            df.Close /= USD_HUF\n",
    "            df.Volume /= USD_HUF\n",
    "\n",
    "        data[ticker] = df.dropna()\n",
    "        \n",
    "    # --- Create a figure. Define a 2 rows x 1 column grid ---\n",
    "    fig = plt.figure(figsize=(8, 7))\n",
    "    gs = gridspec.GridSpec(2, 1, figure=fig)\n",
    "\n",
    "    # --- Daily Closing Price ---\n",
    "    ax_price = fig.add_subplot(gs[0, 0])\n",
    "    for ticker in TICKERS_SAMPLE:\n",
    "        ax_price.plot(data[ticker].Date, data[ticker].Close, '-', markersize=0.2, label=ticker, zorder=2)\n",
    "    ax_price.set_yscale('log')\n",
    "    ax_price.set(xlabel='Time [year]', ylabel='Daily Closing Price [USD]')\n",
    "    ax_price.grid(linestyle=':', linewidth=0.7, zorder=1)\n",
    "    ax_price.label_outer()\n",
    "    ax_price.legend(loc='upper left')\n",
    "    \n",
    "    # --- Daily Traded Volume ---\n",
    "    ax_volume = fig.add_subplot(gs[1, 0])\n",
    "    for ticker in TICKERS_SAMPLE:\n",
    "        ax_volume.plot(data[ticker].Date, data[ticker].Volume, '.', markersize=0.2, label=ticker, zorder=2)\n",
    "    ax_volume.set_yscale('log')\n",
    "    ax_volume.set(xlabel='Time [year]', ylabel='Daily Traded Volume [USD]')\n",
    "    ax_volume.grid(linestyle=':', linewidth=0.7, zorder=1)\n",
    "\n",
    "    # --- Finalize the plot ---      \n",
    "    plt.subplots_adjust(hspace=0.05) # Set spacing between subplots\n",
    "    plt.show()  # Display the plot directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily and Monthly log return\n",
    "\n",
    "<span style=\"font-weight:bold;color:red;background-color:yellow\">TODO: continue here</span>\n",
    "\n",
    "1. Noting that the vertical scale is logarithmic, which stocks have had long periods of exponential growth ?\n",
    "2. In which year did WMT (Walmart) have bigger changes relative to itself: 1975 or 2005 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RangeIndex' object has no attribute 'year'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 79\u001b[0m\n\u001b[0;32m     75\u001b[0m     fig\u001b[38;5;241m.\u001b[39mset_size_inches([\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m15\u001b[39m])\n\u001b[0;32m     76\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 79\u001b[0m daily, monthly \u001b[38;5;241m=\u001b[39m \u001b[43mget_daily_and_monthly_log_returns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m plot_log_returns(daily_log_returns\u001b[38;5;241m=\u001b[39mdaily, monthly_log_returns\u001b[38;5;241m=\u001b[39mmonthly)\n",
      "Cell \u001b[1;32mIn[13], line 45\u001b[0m, in \u001b[0;36mget_daily_and_monthly_log_returns\u001b[1;34m(_data)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ticker, df \u001b[38;5;129;01min\u001b[39;00m _data\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     44\u001b[0m     daily_log_returns[ticker] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshift())\n\u001b[1;32m---> 45\u001b[0m     last_date_of_each_month \u001b[38;5;241m=\u001b[39m \u001b[43mget_last_date_in_each_month\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     df_on_month_last_dates_only \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(df, index\u001b[38;5;241m=\u001b[39mlast_date_of_each_month)\n\u001b[0;32m     47\u001b[0m     monthly_log_returns[ticker] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(df_on_month_last_dates_only[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m\n\u001b[0;32m     48\u001b[0m                                          df_on_month_last_dates_only[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshift())\n",
      "Cell \u001b[1;32mIn[13], line 23\u001b[0m, in \u001b[0;36mget_last_date_in_each_month\u001b[1;34m(series_of_dates)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03mFrom a series_of_dates get the list_of_last_dates_in_each_month\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     22\u001b[0m list_of_last_dates_in_each_month \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 23\u001b[0m groupby_years \u001b[38;5;241m=\u001b[39m series_of_dates\u001b[38;5;241m.\u001b[39mgroupby(\u001b[43mseries_of_dates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myear\u001b[49m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dates_of_year \u001b[38;5;129;01min\u001b[39;00m groupby_years\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m     25\u001b[0m     groupby_months_of_year \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDatetimeIndex(dates_of_year)\u001b[38;5;241m.\u001b[39mgroupby(pd\u001b[38;5;241m.\u001b[39mDatetimeIndex(dates_of_year)\u001b[38;5;241m.\u001b[39mmonth)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RangeIndex' object has no attribute 'year'"
     ]
    }
   ],
   "source": [
    "if True:  # close entire code block here\n",
    "\n",
    "    def get_last_date_in_each_month(series_of_dates):\n",
    "        \"\"\"\n",
    "        From a series_of_dates get the list_of_last_dates_in_each_month\n",
    "        \"\"\"\n",
    "        list_of_last_dates_in_each_month = []\n",
    "        groupby_years = series_of_dates.groupby(series_of_dates.year)\n",
    "        for dates_of_year in groupby_years.values():\n",
    "            groupby_months_of_year = pd.DatetimeIndex(dates_of_year).groupby(pd.DatetimeIndex(dates_of_year).month)\n",
    "            for dates_of_month in groupby_months_of_year.values():\n",
    "                list_of_last_dates_in_each_month.append(max(dates_of_month))\n",
    "\n",
    "        return list_of_last_dates_in_each_month\n",
    "\n",
    "\n",
    "    def get_daily_and_monthly_log_returns(_data):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            yfinance dataframes by ticker\n",
    "\n",
    "        Returns:\n",
    "            {'daily': daily log return by ticker,\n",
    "             'monthly': monthly log return by ticker}\n",
    "        \"\"\"\n",
    "        daily_log_returns = dict()\n",
    "        monthly_log_returns = dict()\n",
    "        for ticker, df in _data.items():\n",
    "            daily_log_returns[ticker] = np.log(df['price'] - df['price'].shift())\n",
    "            last_date_of_each_month = get_last_date_in_each_month(df['price'].index)\n",
    "            df_on_month_last_dates_only = pd.DataFrame(df, index=last_date_of_each_month)\n",
    "            monthly_log_returns[ticker] = np.log(df_on_month_last_dates_only['price'] -\n",
    "                                                 df_on_month_last_dates_only['price'].shift())\n",
    "\n",
    "        return {'daily_log_returns': daily_log_returns, 'monthly_log_returns': monthly_log_returns}\n",
    "\n",
    "\n",
    "    def plot_log_returns(daily_log_returns, monthly_log_returns):\n",
    "\n",
    "        # --- plot daily log returns ---\n",
    "        plt.subplot(211)\n",
    "        for ticker, daily_log_returns_of_ticker in daily_log_returns.items():\n",
    "            r = daily_log_returns_of_ticker\n",
    "            plt.plot(r[r > -1], marker='.', ms=1, label=ticker, lw=0)  # r[r > -1] removes outlier(s)\n",
    "        plt.yscale('linear')\n",
    "        plt.xlabel('Time [year]', fontsize=14)\n",
    "        plt.ylabel('Business Day Log Return', fontsize=14)\n",
    "        plt.xlim([datetime.date(1972,1,1), datetime.date(2025,12,31)])\n",
    "\n",
    "        # --- plot monthly log returns ---\n",
    "        plt.subplot(212)\n",
    "        for ticker, monthly_log_returns_of_ticker in monthly_log_returns.items():\n",
    "            plt.plot(monthly_log_returns_of_ticker, marker='.', ms=1, label=ticker, lw=0)\n",
    "        plt.yscale('linear')\n",
    "        plt.xlabel('Time [year]', fontsize=14)\n",
    "        plt.ylabel('Monthly Log Return', fontsize=14)\n",
    "        plt.xlim([datetime.date(1972,1,1), datetime.date(2025,12,31)])\n",
    "\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches([16, 15])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    daily, monthly = get_daily_and_monthly_log_returns(_data=data)\n",
    "    plot_log_returns(daily_log_returns=daily, monthly_log_returns=monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log return distribution vs Normal\n",
    "\n",
    "$(1)\\,\\,$ On which time scale is BTC closer to normal: daily log returns or monthly log returns ?\n",
    "\n",
    "$(2)\\,\\,$ Can you find any data errors, for example, cutoff around zero ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import erf\n",
    "import pandas as pd\n",
    "\n",
    "PAR['cdf'] = {\n",
    "    'yahoo_codes': YAHOO_CODES,\n",
    "    'yahoo_colors': YAHOO_COLORS,\n",
    "    'code_to_index': {code:index for index, code in enumerate(YAHOO_CODES)},\n",
    "    'selected_code': 'BTC-USD',  # selected data set for plotting\n",
    "    'figure_size': (14, 10),\n",
    "    'fontsize': 14,\n",
    "    'plot_all': False,  # plot all data sets on the right hand side plots ?\n",
    "    'subplots_wspace': 0.2,\n",
    "    'subplots_hspace': 0.5\n",
    "}\n",
    "\n",
    "PAR['cdf']['selected_color'] = PAR['cdf']['yahoo_colors'][PAR['cdf']['code_to_index'][PAR['cdf']['selected_code']]]\n",
    "\n",
    "\n",
    "def get_series_cdf(series=None):\n",
    "    \"\"\"\n",
    "    Calculate CDF (cumulated density function) of a series\n",
    "    \"\"\"\n",
    "    series_dropna = series.dropna()\n",
    "    series_dropna_sorted = np.sort(series_dropna)\n",
    "    n = series_dropna.size\n",
    "    values = np.arange(1, n + 1) / n\n",
    "\n",
    "    return(series_dropna_sorted, values)\n",
    "\n",
    "\n",
    "def get_normal_cdf_value(x=None, mu=None, sigma=None): \n",
    "    \"\"\"\n",
    "    CDF function value of normal distribution with parameters mu, sigma\n",
    "    \"\"\"\n",
    "    return 0.5 * (1.0 + erf((x - mu) / (sigma * np.sqrt(2.0)))) \n",
    "\n",
    "\n",
    "def plot_comparison_to_normal_distribution(par=None, df=None, dfm=None):\n",
    "    \"\"\"\n",
    "    Compare to the normal distribution the daily / monthly log return distributions\n",
    "    \"\"\"\n",
    "\n",
    "    print('\\n\\n\\tSee figures in this order: (1) top left, (2) top right, (3) bottom left, (4) bottom right.\\n\\n'\n",
    "          '\\tAfter that change the \"plot_all\" setting to True and replot all.\\n\\n')\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=2, nrows=2, figsize=par['figure_size'])\n",
    "    for index_of_row, period in enumerate(['DAILY', 'MONTHLY']):\n",
    "        dfsel = {key:df[key].copy() for key in df} if period == 'DAILY' else {key:dfm[key].copy() for key in dfm}\n",
    "\n",
    "        # Left panel: Plot only the one selected time series as an example\n",
    "        cdfx, cdfy = get_series_cdf(dfsel[par['selected_code']]['LogReturn'])  # CDF of daily log returns\n",
    "        popt, pcov = curve_fit(get_normal_cdf_value, cdfx, cdfy)  # fit normal CDF to observed CDF\n",
    "        cdfy_fit = get_normal_cdf_value(cdfx, *popt)  # CDF fit points\n",
    "\n",
    "        ax = axes[index_of_row][0]\n",
    "        ax.set_xlabel(period + ' log return', fontsize=par['fontsize'])\n",
    "        ax.set_ylabel('Cumulated density function  (CDF)', fontsize=par['fontsize'])\n",
    "        ax.set_title(par['selected_code'] + ' : Observed CDF and Normal Fit CDF', fontsize=par['fontsize'])\n",
    "        ax.plot(cdfx, cdfy, c=par['selected_color'], marker='o', label=par['selected_code'], markersize=1, lw=1)\n",
    "        ax.plot(cdfx, cdfy_fit, c='k', ls=':', label='Normal fit',lw=1)\n",
    "        ax.legend(bbox_to_anchor=(.02, .93), loc=2, borderaxespad=0., fontsize=par['fontsize'])\n",
    "        ax.axhline(0, c='k', ls=':', lw=.3)\n",
    "        ax.axhline(1, c='k', ls=':', lw=.3)\n",
    "        ax.axvline(0, c='k', ls=':', lw=.3)\n",
    "\n",
    "        # Right panel: Plot only selected or Plot all\n",
    "        ax = axes[index_of_row][1]\n",
    "        for code, color in zip(par['yahoo_codes'], par['yahoo_colors']):\n",
    "            if par['plot_all'] or not par['plot_all'] and code == par['selected_code']:\n",
    "                cdfx, cdfy = get_series_cdf(dfsel[code]['LogReturn'])  # CDF of daily log returns\n",
    "                popt, pcov = curve_fit(get_normal_cdf_value, cdfx, cdfy)  # fit normal CDF to observed CDF\n",
    "                cdfy_fit = get_normal_cdf_value(cdfx, *popt)  # CDF fit points\n",
    "                ax.plot(cdfy_fit, cdfy, c=color, marker='.', label=code, markersize=1, lw=1)\n",
    "        ax.set_xlabel('Normal fit CDF', fontsize=par['fontsize'])\n",
    "        ax.set_ylabel(f'Observed {period} log returns CDF', fontsize=par['fontsize'])\n",
    "        ax.set_title('Slope > 1 means : observed PDF > normal PDF', fontsize=par['fontsize'])\n",
    "        ax.plot([0,1], [0,1], 'k:', lw=1, label='Slope=1')  # slope=1 for comparison\n",
    "        ax.legend(bbox_to_anchor=(0.02, .98), loc=2, borderaxespad=0., fontsize=par['fontsize'])\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    plt.subplots_adjust(wspace=par['subplots_wspace'], hspace=par['subplots_hspace'])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "df, dfm = read_and_prepare_data(par=PAR['returns'], par_read=PAR['read'])\n",
    "plot_comparison_to_normal_distribution(par=PAR['cdf'], df=df, dfm=dfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log return and Abs value of log return\n",
    "\n",
    "$(1)\\,\\,$ The number beside each symbol shows 1-step autocorrelation, for example, WMT (0.055). Which ticker's log return has negative autocorrelation ?\n",
    "\n",
    "$(2)\\,\\,$ When we switch from log return to the abs value of log return, how does the autocorrelation change ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PAR['log_abs'] = {\n",
    "    'yahoo_codes': YAHOO_CODES,\n",
    "    'yahoo_colors': YAHOO_COLORS,\n",
    "    'xlims': [0, 100],\n",
    "    'ylims': [-.45, .45],\n",
    "    'abs_ylims': [-.02, .45],\n",
    "    'fontsize': 14,\n",
    "    'marker': 'o',\n",
    "    'markersize': 2,\n",
    "    'date_min_max': PAR['returns']['date_min_max'],\n",
    "    'ticks_fontsize': 12,\n",
    "    'subplots_hspace': 0.4,\n",
    "    'figsize_inches': [12, 10]\n",
    "}\n",
    "\n",
    "\n",
    "def plot_log_returns_and_abs_log_returns(par=None, df=None):\n",
    "\n",
    "    print('\\n\\n\\tAutocorrelation (over 1 business day) is shown after each symbol\\n\\n'\n",
    "          '\\tDescribe in a few words each series based on autocorr(log return) and autocorr(abs(log return))\\n\\n')\n",
    "\n",
    "    set_ticks_fontsize(plt=plt, fontsize=par['ticks_fontsize'])\n",
    "\n",
    "    # daily log return\n",
    "    plt.subplot(211)\n",
    "    for code, color in zip(par['yahoo_codes'], par['yahoo_colors']):\n",
    "        s = df[code]['LogReturn']\n",
    "        plt.plot(s, c=color, marker=par['marker'], ms=par['markersize'], label=f'{code} ({s.autocorr():.3f})', lw=0)\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0., fontsize=par['fontsize'])\n",
    "    plt.yscale('linear')\n",
    "    plt.xlabel('Time [year]', fontsize=par['fontsize'])\n",
    "    plt.ylabel('Daily Log Return', fontsize=par['fontsize'])\n",
    "    plt.xlim(par['date_min_max'])\n",
    "    plt.ylim(par['ylims'])\n",
    "\n",
    "    # absolute value of daily log return\n",
    "    plt.subplot(212)\n",
    "    for code, color in zip(par['yahoo_codes'], par['yahoo_colors']):\n",
    "        s = np.absolute(df[code]['LogReturn'])\n",
    "        plt.plot(s, c=color, marker=par['marker'], ms=par['markersize'], label=f'{code} ({s.autocorr():.3f})', lw=0)\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0., fontsize=par['fontsize'])\n",
    "    plt.yscale('linear')\n",
    "    plt.xlabel('Time [year]', fontsize=par['fontsize'])\n",
    "    plt.ylabel('Absolute value of Log Return', fontsize=par['fontsize'])\n",
    "    plt.xlim(par['date_min_max'])\n",
    "    plt.ylim(par['abs_ylims'])\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    plt.subplots_adjust(hspace=par['subplots_hspace'])\n",
    "    fig.set_size_inches(par['figsize_inches'])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "df, _ = read_and_prepare_data(par=PAR['returns'], par_read=PAR['read'])\n",
    "plot_log_returns_and_abs_log_returns(par=PAR['log_abs'], df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorr of log return and abs log return\n",
    "\n",
    "These plots show autocorrelation vs time difference. \n",
    "\n",
    "1. Which daily log return has significantly nonzero autocorrelation ?\n",
    "2. Which abs daily log return has the highest and lowest autocorrelation after long time ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PAR['autocorr'] = {\n",
    "    'yahoo_codes': YAHOO_CODES,\n",
    "    'yahoo_colors': YAHOO_COLORS,\n",
    "    'autocorr_len': 126,  # check autocorrelation up to this number of business days\n",
    "    'xmargin_of_plot': 3,\n",
    "    'fontsize': 14,\n",
    "    'ylims': (-0.2, 0.4),\n",
    "    'yticks': [-0.2, -0.1, 0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'marker': 'o',\n",
    "    'markersize': 4,\n",
    "    'axhline_width': 0.5,\n",
    "    'ticks_fontsize': 12,\n",
    "    'subplots_wspace': 0.03,\n",
    "    'figsize_inches': [15, 7]\n",
    "}\n",
    "\n",
    "PAR['autocorr']['autocorr_shifts'] = np.arange(1 , PAR['autocorr']['autocorr_len'] + 1)\n",
    "PAR['autocorr']['xlims'] = (1 - PAR['autocorr']['xmargin_of_plot'], \n",
    "                            PAR['autocorr']['autocorr_len'] + PAR['autocorr']['xmargin_of_plot'])\n",
    "\n",
    "\n",
    "def plot_autocorr(par=None, df=None):\n",
    "\n",
    "    # daily log return\n",
    "    plt.subplot(121)\n",
    "    for code, color in zip(par['yahoo_codes'], par['yahoo_colors']):\n",
    "        s = df[code]['LogReturn']\n",
    "        autocorr_values = [s.autocorr(shift) for shift in par['autocorr_shifts']]\n",
    "        plt.plot(par['autocorr_shifts'], autocorr_values, c=color,\n",
    "                 marker=par['marker'], ms=par['markersize'], label=code, lw=0)\n",
    "    plt.legend(bbox_to_anchor=(.97, .98), loc=1, borderaxespad=0., fontsize=par['fontsize'])\n",
    "    plt.title('Autocorrelation of daily log return', fontsize=par['fontsize'])\n",
    "    plt.yscale('linear')\n",
    "    plt.xlabel('Shift [business days]', fontsize=par['fontsize'])\n",
    "    plt.ylabel('Autocorrelation with selected shift', fontsize=par['fontsize'])\n",
    "    plt.axhline(0, c='k', ls=':', lw=par['axhline_width'])\n",
    "    plt.axvline(0, c='k', ls=':', lw=par['axhline_width'])\n",
    "    plt.ylim(par['ylims'])\n",
    "    plt.yticks(par['yticks'], [str(_) for _ in par['yticks']])\n",
    "\n",
    "    # daily log return\n",
    "    plt.subplot(122)\n",
    "    for code, color in zip(par['yahoo_codes'], par['yahoo_colors']):\n",
    "        s = np.absolute(df[code]['LogReturn'])\n",
    "        autocorr_values = [s.autocorr(shift) for shift in par['autocorr_shifts']]\n",
    "        plt.plot(par['autocorr_shifts'], autocorr_values, c=color,\n",
    "                 marker=par['marker'], ms=par['markersize'], lw=0)\n",
    "    plt.title('Autocorr. of the **absolute** value of the daily log return', fontsize=par['fontsize'])\n",
    "    plt.yscale('linear')\n",
    "    plt.xlabel('Shift [business days]', fontsize=par['fontsize'])\n",
    "    plt.axhline(0, c='k', ls=':', lw=par['axhline_width'])\n",
    "    plt.axvline(0, c='k', ls=':', lw=par['axhline_width'])\n",
    "    plt.ylim(par['ylims'])\n",
    "    plt.yticks(par['yticks'], ['' for _ in par['yticks']])\n",
    "\n",
    "    set_ticks_fontsize(plt=plt, fontsize=par['ticks_fontsize'])\n",
    "    fig = plt.gcf()\n",
    "    plt.subplots_adjust(wspace=par['subplots_wspace'])\n",
    "    fig.set_size_inches(par['figsize_inches'])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "df, _ = read_and_prepare_data(par=PAR['returns'], par_read=PAR['read'])\n",
    "plot_autocorr(par=PAR['autocorr'], df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume vs log Return\n",
    "\n",
    "1. What do you conclude from daily log return vs traded volume plotted for each day ?\n",
    "2. What do you conclude when points are binned by log return ?\n",
    "3. Do your conclusions change if you select a different time window ( not 2014 - 2019 ) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the Budapest Stock Exchange (bse) time series contain trading volume\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "PAR['volume'] = {\n",
    "    'bse_codes': BSE_CODES,\n",
    "    'bse_colors': BSE_COLORS,\n",
    "    'markersize': 2,\n",
    "    'markersize_large': 5,\n",
    "    'xlimits': (-1.1, 1.1),\n",
    "    'ylimits': (0.007, 500),\n",
    "    'xtics': [-1, -0.75, -0.5, -0.25, 0, 0.25, 0.5, 0.75, 1],\n",
    "    'ytics': [0.01, 0.1, 1, 10, 100],\n",
    "    'axvline_width': 0.5,\n",
    "    'subplots_wspace': 0.03,\n",
    "    'marker': 'o',\n",
    "    'fontsize': 14,\n",
    "    'ticks_fontsize': 12,\n",
    "    'selected_code': None,  # if None, then all are plotted\n",
    "    'figsize_inches': [13, 5]\n",
    "}\n",
    "\n",
    "PAR['volume']['xbins'] = np.linspace(*PAR['volume']['xlimits'], 100)\n",
    "\n",
    "\n",
    "def plot_volume_vs_log_return(par=None, df=df):\n",
    "    \n",
    "    # set index to datetime, set closing value, log return, and traded volume\n",
    "    for code in par['bse_codes']:\n",
    "        df[code].index = pd.to_datetime(df[code]['Date'])\n",
    "        df[code]['Close'] = df[code]['Close price']\n",
    "        df[code]['LogReturn'] = np.log(df[code]['Close price']) - np.log(df[code]['Close price'].shift())\n",
    "        df[code]['Volume'] = df[code]['Volume (HUF value)']\n",
    "\n",
    "    # left subplot\n",
    "    plt.subplot(121)\n",
    "    for code, color in zip(par['bse_codes'], par['bse_colors']):\n",
    "        if par['selected_code'] is None or code == par['selected_code']:\n",
    "            plt.plot(df[code]['LogReturn'], df[code]['Volume'] / 1e+9, c=color, label=code,\n",
    "                     marker=par['marker'], markersize=par['markersize'], lw=0)\n",
    "    plt.xlim(*par['xlimits'])\n",
    "    plt.ylim(*par['ylimits'])\n",
    "    plt.title('Daily traded volume vs log return')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Daily log return', fontsize=par['fontsize'])\n",
    "    plt.xticks(par['xtics'], [f'{xtic:.2g}'.replace('-', '$-$') for xtic in par['xtics']])\n",
    "    plt.ylabel('Traded volume (billion HUF)', fontsize=par['fontsize'])\n",
    "    plt.yticks(par['ytics'], [str(_) for _ in par['ytics']])\n",
    "    plt.axvline(0, c='k', ls=':', lw=par['axvline_width'])\n",
    "\n",
    "    # right subplot\n",
    "    plt.subplot(122)\n",
    "    for code, color in zip(par['bse_codes'], par['bse_colors']):\n",
    "        if par['selected_code'] is None or code == par['selected_code']:\n",
    "            groups = df[code].groupby(pd.cut(df[code]['LogReturn'], par['xbins']))\n",
    "            plot_centers = (par['xbins'][:-1] + par['xbins'][1:]) / 2\n",
    "            plot_values = groups['Volume'].mean() / 1e+9\n",
    "            plt.plot(plot_centers, plot_values, c=color, label=code,\n",
    "                     marker=par['marker'], markersize=par['markersize_large'], lw=0)\n",
    "    plt.xlim(*par['xlimits'])\n",
    "    plt.ylim(*par['ylimits'])\n",
    "    plt.title('Traded volume is averaged in bins of log return')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Daily log return', fontsize=par['fontsize'])\n",
    "    plt.xticks(par['xtics'], [f'{xtic:.2g}'.replace('-', '$-$') for xtic in par['xtics']])\n",
    "    # do not display yticks\n",
    "    plt.yticks(par['ytics'], ['' for ytic in par['ytics']])\n",
    "    plt.axvline(0, c='k', ls=':', lw=par['axvline_width'])\n",
    "    plt.legend(bbox_to_anchor=(0.03, 0.97), loc=2, borderaxespad=0., fontsize=par['fontsize'])\n",
    "\n",
    "    set_ticks_fontsize(plt=plt, fontsize=par['ticks_fontsize'])\n",
    "    fig = plt.gcf()\n",
    "    plt.subplots_adjust(wspace=par['subplots_wspace'])\n",
    "    fig.set_size_inches(par['figsize_inches'])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "df, _ = read_and_prepare_data(par=PAR['returns'], par_read=PAR['read'])\n",
    "plot_volume_vs_log_return(par=PAR['volume'], df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume vs Volatility of daily close\n",
    "\n",
    "1. Based on the below scatter plot what do you conclude for the relationship between daily log(volume) and log(volatility) ?\n",
    "2. Based on the roughly even distribution of the daily points in the plot what is your chance of having a high volume day ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "PAR['volume_vs_volatility'] = {\n",
    "    'bse_codes': BSE_CODES,\n",
    "    'bse_colors': BSE_COLORS,\n",
    "    'markersize': 4,\n",
    "    'marker': 'o',\n",
    "    'fontsize': 14,\n",
    "    'ticks_fontsize': 13,\n",
    "    'xtics': [10, 100, 1000],\n",
    "    'ytics': [0.1, 1, 10],\n",
    "    'selected_code': None,  # if None, then all are plotted\n",
    "    'figsize_inches': [8, 6]\n",
    "}\n",
    "\n",
    "\n",
    "def calculate_bse_monthly_volatility_and_average_traded_volume(data=None):\n",
    "    '''\n",
    "    For the BSE (Budapest Stock Exchange) data sets:\n",
    "    for each month calculate the volatility of the daily close and the average daily traded volume.    \n",
    "    '''\n",
    "    monthly_data = pd.DataFrame(columns=['volatility', 'average_volume'])\n",
    "    dates = data.index\n",
    "    yearly_dates = dates.groupby(dates.year)\n",
    "    for year in yearly_dates.keys():\n",
    "        monthly_dates = pd.DatetimeIndex(yearly_dates[year]).groupby(pd.DatetimeIndex(yearly_dates[year]).month)\n",
    "        for month in monthly_dates.keys():\n",
    "            date_all = monthly_dates[month]\n",
    "            date_first = min(date_all)\n",
    "            close_daily_all = [data.loc[date]['Close price'] for date in date_all]\n",
    "            volume_daily_all = [data.loc[date]['Volume (HUF value)'] for date in date_all]\n",
    "            volatility = np.std(close_daily_all)\n",
    "            volume_daily_average = np.average(volume_daily_all)\n",
    "            monthly_data.loc[date_first] = [volatility, volume_daily_average]\n",
    "\n",
    "    return monthly_data\n",
    "\n",
    "\n",
    "def plot_bse_volume_vs_volatility(par=None, df=None):\n",
    "    \"\"\"\n",
    "    For the BSE (Budapest Stock Exchange) data sets:\n",
    "    plot the monthly volatilty vs avg daily volume of the month.\n",
    "    \"\"\"\n",
    "    \n",
    "    monthly_data = {}\n",
    "    for code, color in zip(par['bse_codes'], par['bse_colors']):\n",
    "        if par['selected_code'] is None or code == par['selected_code']:\n",
    "            monthly_data[code] = calculate_bse_monthly_volatility_and_average_traded_volume(data=df[code])\n",
    "            plt.plot(monthly_data[code]['volatility'], monthly_data[code]['average_volume'] / 1e+9,\n",
    "                     c=color, marker=par['marker'], label=code, lw=0, markersize=par['markersize'])\n",
    "    plt.legend(bbox_to_anchor=(.92, .08), loc=4, borderaxespad=0., fontsize=par['fontsize'])\n",
    "    plt.title('Monthly data: Average daily volume vs Volatility of daily close', fontsize=par['fontsize'])\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Volatility of daily close in a month (HUF)', fontsize=par['fontsize'])\n",
    "    plt.ylabel('Average daily volume in a month (billion HUF)', fontsize=par['fontsize'])\n",
    "    plt.xticks(par['xtics'], [f'{xtic:g}' for xtic in par['xtics']])\n",
    "    plt.yticks(par['ytics'], [f'{ytic:g}' for ytic in par['ytics']])\n",
    "\n",
    "    set_ticks_fontsize(plt=plt, fontsize=par['ticks_fontsize'])\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(par['figsize_inches'])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "df, _ = read_and_prepare_data(par=PAR['returns'], par_read=PAR['read'])\n",
    "plot_bse_volume_vs_volatility(par=PAR['volume_vs_volatility'], df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewness of log returns distribution \n",
    "\n",
    "1. What does the sum of the highest and the lowest value tell about a distribution ?\n",
    "2. Does the negative skew of SP500 mean that stock prices respond faster to negative news than to positive news ?\n",
    "\n",
    "\n",
    "| Name | Symbol and Calculation |\n",
    "|:-----|:------------|\n",
    "| Random variable | $X$ |\n",
    "| Mean | $\\mu = E\\left[ \\,X \\,\\right]$ |\n",
    "| Variance | ${\\displaystyle \\sigma^{\\,2} = E\\left[ \\, \\left( \\, X - \\mu \\, \\right)^{\\,2} \\, \\right] }$ |\n",
    "| Volatility = Std.dev. | $\\sigma$ |\n",
    "| Skewness | ${\\displaystyle E\\left[\\,\\left(\\frac{X-\\mu}{\\sigma}\\,\\right)^{\\,3} \\, \\right]}$|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from os.path import join\n",
    "\n",
    "PAR['skewness'] = {\n",
    "    # select data sets to be analyzed and set their display names\n",
    "    'fred_selected_codes': {\n",
    "        'GOLDPMGBD228NLBM': 'GOLD',\n",
    "        'DEXJPUS':'JPYUSD', \n",
    "        'ICERATES1500USD1Y': 'US1YSW',\n",
    "        'SP500': 'SP500',\n",
    "        'WILLRESIPR': 'WILLSH'\n",
    "    },\n",
    "    'data_dir': 'data'\n",
    "}\n",
    "\n",
    "\n",
    "def read_fred_selected(par=None):\n",
    "    \"\"\"\n",
    "    Read FRED data sets without the lines containing a dot instead of data\n",
    "    Calculate also the log returns\n",
    "    \"\"\"\n",
    "    df = {}\n",
    "\n",
    "    for code in par['fred_selected_codes']:\n",
    "        df[code] = pd.read_csv(join(par['data_dir'], code + '.csv'), na_values=['.'])\n",
    "        df[code].dropna(inplace=True)\n",
    "        df[code]['LogReturn'] = np.log(df[code][code]) - np.log(df[code][code]).shift()\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_skewness(par=None, df=None):\n",
    "    \"\"\"\n",
    "    For the selected FRED data sets write their skewness to stdout and plot differences among the skewnesses\n",
    "    \"\"\"\n",
    "\n",
    "    df_out = pd.DataFrame(columns=['Skew', 'First+Last', 'Name'])\n",
    "    \n",
    "    for index, code in enumerate(par['fred_selected_codes']):\n",
    "        log_returns = df[code]['LogReturn'].dropna()\n",
    "        sorted_log_returns = pd.Series.sort_values(log_returns).tolist()  # sort into ascending order\n",
    "\n",
    "        df_out.loc[index] = [\n",
    "            f'{stats.skew(sorted_log_returns):+.2f}',\n",
    "            f'{sorted_log_returns[0] + sorted_log_returns[-1]:+.3f}',\n",
    "            par['fred_selected_codes'][code]\n",
    "        ]\n",
    "\n",
    "    df_out.set_index('Name', inplace=True)    \n",
    "    return df_out\n",
    "\n",
    "        \n",
    "df = read_fred_selected(par=PAR['skewness'])\n",
    "df_out = get_skewness(par=PAR['skewness'], df=df)\n",
    "display(df_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: yearly mean of daily log returns and yearly volatility\n",
    "For each year separately, calculate (1) the mean of the daily log return of WMT, and (2) the volatility of the daily log returns of WMT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "\n",
    "PAR['mean_vol'] = {\n",
    "    'fontsize': 12,\n",
    "    'data_dir': 'data',\n",
    "    'selected_data_set': 'WMT',\n",
    "    'figure_size': (9, 6)\n",
    "}\n",
    "\n",
    "\n",
    "def yearly_mean_and_vol_of_daily_log_return(par=None):\n",
    "    \n",
    "    # data processing\n",
    "    df = pd.read_csv(join(par['data_dir'], par['selected_data_set'] + '.csv'))\n",
    "    df['Year'] = pd.to_datetime(df.Date).dt.year\n",
    "    df['LogReturnDaily'] = np.log(df['Close']) - np.log(df['Close'].shift())\n",
    "    daily_log_ret_yearly_mean = df.groupby(df.Year).LogReturnDaily.agg('mean')\n",
    "    daily_log_ret_vol = df.groupby(df.Year).LogReturnDaily.agg('std')\n",
    "\n",
    "    # plotting\n",
    "    fig, axes = plt.subplots(figsize=par['figure_size'])\n",
    "    plt.plot(daily_log_ret_yearly_mean, markersize=10, marker='.', linestyle=':', linewidth=1, color='g')\n",
    "    plt.plot(daily_log_ret_vol, markersize=10, marker='.', linestyle=':', linewidth=1, color='b')\n",
    "    plt.title(f'Yearly mean (green) and volatility (blue) of the daily log returns of ' + par['selected_data_set'],\n",
    "              fontsize=par['fontsize'])\n",
    "    plt.xlabel('Y e a r', fontsize=par['fontsize'])\n",
    "    plt.ylabel('Daily log returns: avg. and std.dev', fontsize=par['fontsize'])\n",
    "    plt.axhline(0, c='k', ls=':', lw=.3)\n",
    "    plt.show()\n",
    "\n",
    "    # investigate the average returns in sorted order\n",
    "    print('Yearly mean of daily log returns in sorted order\\n')\n",
    "    display(daily_log_ret_yearly_mean.sort_values())\n",
    "\n",
    "\n",
    "yearly_mean_and_vol_of_daily_log_return(par=PAR['mean_vol'])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.266px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
